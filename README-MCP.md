# ğŸ§  Jarvis MCP - Ã‰cosystÃ¨me IA Intelligent

> **Orchestration d'agents IA via Model Context Protocol (MCP)**
> 
> Un hub central pour coordonner Ollama (local), Perplexity (recherche), Memory (contexte) et Tools (utilitaires) via le protocole MCP standardisÃ©.

## ğŸ—ï¸ Architecture MCP

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MCP HUB CENTRAL                       â”‚
â”‚                   (Port 4000)                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ â€¢ Routage intelligent des requÃªtes                 â”‚ â”‚
â”‚  â”‚ â€¢ Orchestration multi-agents                       â”‚ â”‚
â”‚  â”‚ â€¢ Optimisation de prompts contextuels             â”‚ â”‚
â”‚  â”‚ â€¢ WebSocket temps rÃ©el                             â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚             â”‚             â”‚
   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”    â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”
   â”‚Ollama  â”‚    â”‚Perplex.â”‚    â”‚Memory  â”‚    â”‚Tools   â”‚
   â”‚MCP     â”‚    â”‚MCP     â”‚    â”‚MCP     â”‚    â”‚MCP     â”‚
   â”‚:4003   â”‚    â”‚:4004   â”‚    â”‚:4005   â”‚    â”‚:4006   â”‚
   â”‚        â”‚    â”‚        â”‚    â”‚        â”‚    â”‚        â”‚
   â”‚ğŸ¦™ Localâ”‚    â”‚ğŸ” Searchâ”‚    â”‚ğŸ’¾ SQLiteâ”‚    â”‚ğŸ› ï¸ Utilsâ”‚
   â”‚AI      â”‚    â”‚API     â”‚    â”‚Context â”‚    â”‚Files   â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ DÃ©marrage Rapide

### PrÃ©requis
```bash
# Ollama doit Ãªtre dÃ©marrÃ© en local
ollama serve

# Variables d'environnement (optionnelles)
export PERPLEXITY_API_KEY="your_perplexity_api_key"
```

### DÃ©marrage de l'Ã©cosystÃ¨me
```bash
# Donner les permissions d'exÃ©cution
chmod +x start-mcp-hub.sh

# DÃ©marrer tous les services MCP
./start-mcp-hub.sh
```

### VÃ©rification du statut
```bash
# VÃ©rifier que tous les services sont actifs
curl http://localhost:4000/mcp/status

# Interface web
open http://localhost:4002
```

## ğŸ”— Services MCP

### ğŸ—ï¸ MCP Hub Central (Port 4000)
**Orchestrateur principal pour tous les agents IA**

- **Endpoint principal:** `http://localhost:4000`
- **Documentation:** `http://localhost:4000/docs`
- **Status:** `http://localhost:4000/mcp/status`

**FonctionnalitÃ©s:**
- Routage intelligent selon la complexitÃ© des requÃªtes
- Optimisation automatique des prompts
- Gestion de la mÃ©moire vectorielle
- Communication WebSocket temps rÃ©el
- Load balancing entre agents

### ğŸ¦™ Ollama MCP Server (Port 4003) 
**Assistant IA local pour dÃ©veloppement**

**CapacitÃ©s MCP:**
- `ollama_chat`: Chat avec contexte projet
- `ollama_analyze_code`: Analyse spÃ©cialisÃ©e de code
- `ollama_optimize_prompt`: Optimisation pour autres AIs

**ModÃ¨les supportÃ©s:**
- `llama3.2:3b` (rapide, requÃªtes simples)
- `llama3.2:8b` (complexe, analyse de code)

### ğŸ” Perplexity MCP Server (Port 4004)
**Recherche en temps rÃ©el et actualitÃ©s tech**

**CapacitÃ©s MCP:**
- `perplexity_search`: Recherche contextuelle
- `perplexity_research`: Recherche multi-angles
- `perplexity_tech_news`: ActualitÃ©s technologiques
- `perplexity_compare`: Comparaison de technologies

**ModÃ¨les:**
- `llama-3.1-sonar-small-128k-online` (rapide)
- `llama-3.1-sonar-large-128k-online` (approfondi)

### ğŸ’¾ Memory MCP Server (Port 4005)
**Gestion intelligente du contexte et historique**

**CapacitÃ©s MCP:**
- `memory_store`: Stockage conversations
- `memory_get_context`: RÃ©cupÃ©ration contexte pertinent
- `memory_optimize_prompt`: Optimisation basÃ©e sur l'historique
- `memory_search`: Recherche dans l'historique
- `memory_stats`: Statistiques d'usage

**Base de donnÃ©es:** SQLite avec indexation sÃ©mantique

### ğŸ› ï¸ Tools MCP Server (Port 4006)
**Utilitaires systÃ¨me et manipulation de fichiers**

**CapacitÃ©s MCP:**
- `file_read/write/list`: Gestion fichiers sÃ©curisÃ©e
- `web_fetch`: RÃ©cupÃ©ration de contenu web
- `command_run`: ExÃ©cution commandes (whitelist)
- `code_analyze`: Analyse statique de code
- `backup_create`: Sauvegarde du workspace

## ğŸŒ Interface Web (Port 4002)

**Interface simple et moderne pour interagir avec l'Ã©cosystÃ¨me MCP**

### FonctionnalitÃ©s:
- **Chat Multi-Agents:** SÃ©lection automatique ou manuelle de l'agent
- **Optimisation de Prompts:** GÃ©nÃ©ration de prompts optimisÃ©s pour Claude/ChatGPT
- **Historique Intelligent:** Recherche et rÃ©utilisation du contexte
- **Statistiques en Temps RÃ©el:** Monitoring des performances
- **Interface Responsive:** Compatible mobile/desktop

### Agents disponibles:
- ğŸ¦™ **Ollama Local:** Rapide, ideal pour dÃ©veloppement
- ğŸ” **Perplexity Pro:** Recherche en temps rÃ©el, actualitÃ©s
- ğŸ¤– **Claude Code:** GÃ©nÃ©ration prompts optimisÃ©s
- ğŸ’­ **ChatGPT:** GÃ©nÃ©ration prompts optimisÃ©s

## ğŸ“¡ API MCP Hub

### Endpoints principaux

```bash
# Chat avec agent automatique
POST /mcp/chat
{
  "message": "Comment optimiser une base de donnÃ©es ?",
  "agent": "auto|ollama|perplexity",
  "project": "mon-projet",
  "context": "FastAPI + SQLite"
}

# Optimisation de prompt
POST /mcp/optimize-prompt  
{
  "original_prompt": "Explain this code",
  "target_ai": "claude|chatgpt|perplexity",
  "context": "React component",
  "project": "frontend-app"
}

# Statut de l'Ã©cosystÃ¨me
GET /mcp/status

# Historique conversations
GET /mcp/conversations?limit=10&project=my-project
```

### RÃ©ponses types
```json
{
  "response": "...",
  "agent_used": "ollama",
  "optimized_prompt": "...",
  "context_applied": "...",
  "timestamp": "2024-12-20T...",
  "conversation_id": 123
}
```

## âš™ï¸ Configuration AvancÃ©e

### Variables d'environnement
```bash
# Perplexity API (optionnel)
PERPLEXITY_API_KEY=your_key

# Ollama (local)
OLLAMA_HOST=localhost:11434

# Ports personnalisÃ©s (dÃ©faut: 4000-4006)
MCP_HUB_PORT=4000
OLLAMA_MCP_PORT=4003
PERPLEXITY_MCP_PORT=4004
MEMORY_MCP_PORT=4005
TOOLS_MCP_PORT=4006
FRONTEND_PORT=4002
```

### Configuration Ollama
```bash
# Installer des modÃ¨les supplÃ©mentaires
ollama pull llama3.2:8b
ollama pull codellama:7b
ollama pull mistral:7b

# VÃ©rifier les modÃ¨les disponibles
ollama list
```

## ğŸ§ª Tests et Debugging

### Tests de santÃ© des services
```bash
# Test individuel des services MCP
curl http://localhost:4003/health  # Ollama MCP
curl http://localhost:4004/health  # Perplexity MCP  
curl http://localhost:4005/health  # Memory MCP
curl http://localhost:4006/health  # Tools MCP

# Test du hub central
curl http://localhost:4000/mcp/status
```

### Tests de chat
```bash
# Test Ollama via MCP Hub
curl -X POST http://localhost:4000/mcp/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Bonjour!", "agent": "ollama"}'

# Test Perplexity via MCP Hub  
curl -X POST http://localhost:4000/mcp/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Latest AI news", "agent": "perplexity"}'
```

### Logs et monitoring
```bash
# Voir les logs en temps rÃ©el
docker-compose -f docker-compose.mcp.yml logs -f

# Logs d'un service spÃ©cifique
docker-compose -f docker-compose.mcp.yml logs -f mcp-hub
docker-compose -f docker-compose.mcp.yml logs -f ollama-mcp
```

## ğŸ”§ Maintenance

### ArrÃªt et redÃ©marrage
```bash
# ArrÃªter l'Ã©cosystÃ¨me
docker-compose -f docker-compose.mcp.yml down

# RedÃ©marrer un service spÃ©cifique  
docker-compose -f docker-compose.mcp.yml restart mcp-hub

# Reconstruction complÃ¨te
docker-compose -f docker-compose.mcp.yml up --build -d
```

### Nettoyage
```bash
# Nettoyer les containers et volumes
docker-compose -f docker-compose.mcp.yml down -v
docker system prune -f

# Nettoyer les ports 4000-4010
./start-mcp-hub.sh  # Le script nettoie automatiquement
```

## ğŸ¯ Cas d'Usage

### 1. DÃ©veloppement Local
- **Ollama** pour l'assistance code rapide
- **Memory** pour maintenir le contexte projet
- **Tools** pour l'analyse de fichiers

### 2. Recherche et Veille Tech
- **Perplexity** pour les derniÃ¨res actualitÃ©s
- **Memory** pour stocker les insights
- **Hub** pour synthÃ©tiser les informations

### 3. Optimisation de Prompts
- **Ollama** analyse votre contexte  
- **Memory** rÃ©cupÃ¨re l'historique pertinent
- **Hub** gÃ©nÃ¨re des prompts optimisÃ©s pour Claude/ChatGPT

### 4. Orchestration Multi-Agents
- **Routage automatique** selon la complexitÃ©
- **Contexte partagÃ©** entre tous les agents
- **Apprentissage** des prÃ©fÃ©rences utilisateur

## ğŸ” DÃ©pannage

### ProblÃ¨mes courants

**Ollama non accessible:**
```bash
# VÃ©rifier qu'Ollama est dÃ©marrÃ©
ollama serve
curl http://localhost:11434/api/tags
```

**Ports occupÃ©s:**
```bash
# Le script start-mcp-hub.sh nettoie automatiquement
# Ou manuellement:
lsof -ti :4000 | xargs kill -9
```

**Perplexity API limitÃ©e:**
```bash
# L'Ã©cosystÃ¨me fonctionne sans clÃ© Perplexity
# Seuls les tests Perplexity Ã©choueront
```

**ProblÃ¨mes CORS Frontend:**
```bash
# Le frontend est configurÃ© pour CORS
# VÃ©rifier que MCP Hub autorise les CORS
curl -H "Origin: http://localhost:4002" http://localhost:4000/mcp/status
```

## ğŸš€ Roadmap

### Prochaines fonctionnalitÃ©s
- [ ] Support Claude API direct (en plus des prompts)
- [ ] Interface vocale avec reconnaissance/synthÃ¨se
- [ ] Plugins personnalisÃ©s pour nouveaux agents
- [ ] Dashboard d'analytics avancÃ©
- [ ] API REST complÃ¨te pour intÃ©grations externes
- [ ] Support multi-utilisateurs avec authentification

---

**ğŸ‰ L'Ã©cosystÃ¨me Jarvis MCP est maintenant opÃ©rationnel !**

AccÃ©dez Ã  l'interface sur `http://localhost:4002` et commencez Ã  orchestrer vos agents IA de maniÃ¨re intelligente.