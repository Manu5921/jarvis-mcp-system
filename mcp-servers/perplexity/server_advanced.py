"""
Advanced MCP Perplexity Server with Real Pro Integration
Implements intelligent search, research capabilities, and real-time information access
"""

import asyncio
import json
import logging
import os
import uuid
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
import httpx
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
import uvicorn

# Configuration
PERPLEXITY_SERVER_PORT = 4004
PERPLEXITY_API_KEY = os.getenv("PERPLEXITY_API_KEY", "")
PERPLEXITY_API_BASE = "https://api.perplexity.ai"
MAX_SEARCH_RESULTS = 10
RATE_LIMIT_PER_MINUTE = 60

# Logging setup
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

# MCP Protocol Models
class MCPInitRequest(BaseModel):
    client_info: Dict[str, str]

class MCPInitResponse(BaseModel):
    session_id: str
    server_info: Dict[str, str]
    capabilities: Dict[str, Any]

class MCPToolCallRequest(BaseModel):
    arguments: Dict[str, Any]
    session_id: Optional[str] = None

class MCPToolResponse(BaseModel):
    content: List[Dict[str, Any]]
    is_error: bool = False

class MCPTool(BaseModel):
    name: str
    description: str
    input_schema: Dict[str, Any]

class MCPResource(BaseModel):
    uri: str
    name: str
    description: str
    mime_type: str

# Session management and rate limiting
active_sessions: Dict[str, Dict] = {}
request_history: List[datetime] = []

# FastAPI app
app = FastAPI(
    title="Advanced MCP Perplexity Server",
    version="2.0.0",
    description="Intelligent search and research with Perplexity Pro integration"
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

def _check_rate_limit() -> bool:
    """Check if we're within rate limits"""
    global request_history
    now = datetime.now()
    # Remove requests older than 1 minute
    request_history = [req_time for req_time in request_history if now - req_time < timedelta(minutes=1)]
    
    if len(request_history) >= RATE_LIMIT_PER_MINUTE:
        return False
    
    request_history.append(now)
    return True

def _has_api_key() -> bool:
    """Check if Perplexity API key is available"""
    return bool(PERPLEXITY_API_KEY and PERPLEXITY_API_KEY != "")

# MCP Protocol Endpoints
@app.post("/mcp/initialize")
async def initialize_mcp_session(request: MCPInitRequest) -> MCPInitResponse:
    """Initialize MCP session with Perplexity capabilities"""
    session_id = str(uuid.uuid4())
    
    api_available = _has_api_key()
    
    active_sessions[session_id] = {
        "created_at": datetime.now(),
        "client_info": request.client_info,
        "search_count": 0,
        "research_count": 0,
        "last_activity": datetime.now(),
        "api_available": api_available
    }
    
    logger.info(f"‚úÖ Perplexity MCP Session initialized: {session_id} "
                f"(API: {'‚úÖ' if api_available else '‚ùå Missing API key'})")
    
    return MCPInitResponse(
        session_id=session_id,
        server_info={
            "name": "jarvis-perplexity-server",
            "version": "2.0.0",
            "description": "Advanced search and research with Perplexity Pro"
        },
        capabilities={
            "tools": {
                "list_changed": True,
                "supports_progress": True,
                "supports_streaming": True
            },
            "resources": {
                "list_changed": True,
                "supports_templates": True
            },
            "experimental": {
                "real_time_search": api_available,
                "research_mode": True,
                "source_verification": True,
                "multi_query_search": True
            },
            "perplexity": {
                "api_available": api_available,
                "rate_limit": RATE_LIMIT_PER_MINUTE,
                "max_results": MAX_SEARCH_RESULTS
            }
        }
    )

@app.get("/mcp/tools")
async def list_mcp_tools():
    """List all available Perplexity tools"""
    tools = [
        MCPTool(
            name="search_web",
            description="Search the web with Perplexity's real-time capabilities",
            input_schema={
                "type": "object",
                "properties": {
                    "query": {"type": "string", "description": "Search query"},
                    "focus": {"type": "string", "description": "Search focus: general, academic, news, technical"},
                    "recency": {"type": "string", "description": "Time filter: hour, day, week, month, year"},
                    "max_results": {"type": "integer", "default": 5, "description": "Maximum results"},
                    "include_sources": {"type": "boolean", "default": True, "description": "Include source citations"},
                    "language": {"type": "string", "default": "en", "description": "Search language"}
                },
                "required": ["query"]
            }
        ),
        MCPTool(
            name="research_topic",
            description="Conduct comprehensive research on a topic",
            input_schema={
                "type": "object",
                "properties": {
                    "topic": {"type": "string", "description": "Research topic"},
                    "depth": {"type": "string", "description": "Research depth: overview, detailed, comprehensive"},
                    "perspective": {"type": "string", "description": "Research perspective: neutral, academic, practical"},
                    "include_recent": {"type": "boolean", "default": True, "description": "Include recent developments"},
                    "include_context": {"type": "boolean", "default": True, "description": "Include background context"},
                    "target_audience": {"type": "string", "description": "Target audience level"}
                },
                "required": ["topic"]
            }
        ),
        MCPTool(
            name="fact_check",
            description="Verify facts and claims using authoritative sources",
            input_schema={
                "type": "object",
                "properties": {
                    "claim": {"type": "string", "description": "Claim or statement to fact-check"},
                    "context": {"type": "string", "description": "Additional context for the claim"},
                    "source_priority": {"type": "string", "description": "Source priority: academic, news, government, all"},
                    "include_confidence": {"type": "boolean", "default": True, "description": "Include confidence score"},
                    "detailed_analysis": {"type": "boolean", "default": False, "description": "Provide detailed analysis"}
                },
                "required": ["claim"]
            }
        ),
        MCPTool(
            name="compare_sources",
            description="Compare information from multiple sources on a topic",
            input_schema={
                "type": "object",
                "properties": {
                    "topic": {"type": "string", "description": "Topic to compare"},
                    "source_types": {"type": "array", "items": {"type": "string"}, "description": "Types of sources to compare"},
                    "focus_areas": {"type": "array", "items": {"type": "string"}, "description": "Specific areas to focus comparison"},
                    "include_bias_analysis": {"type": "boolean", "default": True, "description": "Include bias analysis"},
                    "summarize_differences": {"type": "boolean", "default": True, "description": "Summarize key differences"}
                },
                "required": ["topic"]
            }
        ),
        MCPTool(
            name="trending_search",
            description="Find trending topics and current events",
            input_schema={
                "type": "object",
                "properties": {
                    "category": {"type": "string", "description": "Category: tech, science, politics, business, entertainment"},
                    "region": {"type": "string", "default": "global", "description": "Geographic region"},
                    "time_frame": {"type": "string", "default": "day", "description": "Time frame: hour, day, week"},
                    "include_analysis": {"type": "boolean", "default": True, "description": "Include trend analysis"},
                    "max_trends": {"type": "integer", "default": 10, "description": "Maximum trends to return"}
                },
                "required": []
            }
        ),
        MCPTool(
            name="expert_opinion",
            description="Find expert opinions and authoritative sources on a topic",
            input_schema={
                "type": "object",
                "properties": {
                    "topic": {"type": "string", "description": "Topic to find expert opinions on"},
                    "expertise_area": {"type": "string", "description": "Area of expertise to focus on"},
                    "source_credibility": {"type": "string", "default": "high", "description": "Required credibility level"},
                    "include_credentials": {"type": "boolean", "default": True, "description": "Include expert credentials"},
                    "recent_only": {"type": "boolean", "default": False, "description": "Only recent opinions"}
                },
                "required": ["topic"]
            }
        ),
        MCPTool(
            name="multi_perspective_search",
            description="Search from multiple perspectives on a topic",
            input_schema={
                "type": "object",
                "properties": {
                    "topic": {"type": "string", "description": "Topic to explore"},
                    "perspectives": {"type": "array", "items": {"type": "string"}, "description": "Perspectives to explore"},
                    "balance_viewpoints": {"type": "boolean", "default": True, "description": "Balance different viewpoints"},
                    "include_evidence": {"type": "boolean", "default": True, "description": "Include supporting evidence"},
                    "synthesis": {"type": "boolean", "default": True, "description": "Provide synthesis of perspectives"}
                },
                "required": ["topic"]
            }
        ),
        MCPTool(
            name="source_analysis",
            description="Analyze the credibility and quality of sources",
            input_schema={
                "type": "object",
                "properties": {
                    "source_url": {"type": "string", "description": "URL of source to analyze"},
                    "content_snippet": {"type": "string", "description": "Content snippet to analyze"},
                    "analysis_depth": {"type": "string", "default": "standard", "description": "Analysis depth level"},
                    "check_bias": {"type": "boolean", "default": True, "description": "Check for bias"},
                    "verify_claims": {"type": "boolean", "default": True, "description": "Verify factual claims"}
                },
                "required": []
            }
        ),
        MCPTool(
            name="real_time_monitoring",
            description="Monitor real-time developments on a topic",
            input_schema={
                "type": "object",
                "properties": {
                    "topic": {"type": "string", "description": "Topic to monitor"},
                    "keywords": {"type": "array", "items": {"type": "string"}, "description": "Keywords to track"},
                    "alert_threshold": {"type": "string", "default": "significant", "description": "Alert threshold level"},
                    "include_sentiment": {"type": "boolean", "default": True, "description": "Include sentiment analysis"},
                    "monitor_duration": {"type": "string", "default": "1hour", "description": "Monitoring duration"}
                },
                "required": ["topic"]
            }
        )
    ]
    
    return {"tools": [tool.dict() for tool in tools]}

@app.get("/mcp/resources")
async def list_mcp_resources():
    """List available Perplexity resources"""
    resources = [
        MCPResource(
            uri="docs://perplexity-server",
            name="Perplexity Server Documentation",
            description="Complete documentation for Perplexity integration",
            mime_type="text/markdown"
        ),
        MCPResource(
            uri="trends://current",
            name="Current Trends",
            description="Real-time trending topics and current events",
            mime_type="application/json"
        ),
        MCPResource(
            uri="sources://credible",
            name="Credible Sources Database",
            description="Database of verified credible sources",
            mime_type="application/json"
        ),
        MCPResource(
            uri="stats://usage",
            name="Usage Statistics",
            description="Search and research usage statistics",
            mime_type="application/json"
        )
    ]
    
    return {"resources": [resource.dict() for resource in resources]}

# Tool Implementation Endpoints
@app.post("/mcp/tools/search_web/call")
async def tool_search_web(request: MCPToolCallRequest) -> MCPToolResponse:
    """Search the web using Perplexity or fallback methods"""
    try:
        query = request.arguments["query"]
        focus = request.arguments.get("focus", "general")
        recency = request.arguments.get("recency", "month")
        max_results = request.arguments.get("max_results", 5)
        include_sources = request.arguments.get("include_sources", True)
        language = request.arguments.get("language", "en")
        
        # Check rate limits
        if not _check_rate_limit():
            raise HTTPException(status_code=429, detail="Rate limit exceeded")
        
        session_id = request.session_id
        if session_id in active_sessions:
            active_sessions[session_id]["search_count"] += 1
            active_sessions[session_id]["last_activity"] = datetime.now()
        
        # Use real Perplexity API if available
        if _has_api_key():
            results = await _search_with_perplexity_api(query, focus, recency, max_results, language)
        else:
            # Fallback to simulated search
            results = _simulate_perplexity_search(query, focus, recency, max_results, include_sources)
        
        return MCPToolResponse(
            content=[{
                "type": "text",
                "text": json.dumps({
                    "query": query,
                    "results": results,
                    "search_params": {
                        "focus": focus,
                        "recency": recency,
                        "max_results": max_results,
                        "language": language
                    },
                    "metadata": {
                        "api_used": _has_api_key(),
                        "timestamp": datetime.now().isoformat(),
                        "total_results": len(results)
                    }
                }, indent=2)
            }]
        )
        
    except Exception as e:
        logger.error(f"Error searching web: {e}")
        return MCPToolResponse(
            content=[{
                "type": "text",
                "text": f"Error searching web: {str(e)}"
            }],
            is_error=True
        )

@app.post("/mcp/tools/research_topic/call")
async def tool_research_topic(request: MCPToolCallRequest) -> MCPToolResponse:
    """Conduct comprehensive research on a topic"""
    try:
        topic = request.arguments["topic"]
        depth = request.arguments.get("depth", "detailed")
        perspective = request.arguments.get("perspective", "neutral")
        include_recent = request.arguments.get("include_recent", True)
        include_context = request.arguments.get("include_context", True)
        target_audience = request.arguments.get("target_audience", "general")
        
        # Check rate limits
        if not _check_rate_limit():
            raise HTTPException(status_code=429, detail="Rate limit exceeded")
        
        session_id = request.session_id
        if session_id in active_sessions:
            active_sessions[session_id]["research_count"] += 1
            active_sessions[session_id]["last_activity"] = datetime.now()
        
        # Conduct multi-faceted research
        research_result = await _conduct_comprehensive_research(
            topic, depth, perspective, include_recent, include_context, target_audience
        )
        
        return MCPToolResponse(
            content=[{
                "type": "text",
                "text": json.dumps(research_result, indent=2)
            }]
        )
        
    except Exception as e:
        logger.error(f"Error researching topic: {e}")
        return MCPToolResponse(
            content=[{
                "type": "text",
                "text": f"Error researching topic: {str(e)}"
            }],
            is_error=True
        )

@app.post("/mcp/tools/fact_check/call")
async def tool_fact_check(request: MCPToolCallRequest) -> MCPToolResponse:
    """Fact-check claims using authoritative sources"""
    try:
        claim = request.arguments["claim"]
        context = request.arguments.get("context", "")
        source_priority = request.arguments.get("source_priority", "all")
        include_confidence = request.arguments.get("include_confidence", True)
        detailed_analysis = request.arguments.get("detailed_analysis", False)
        
        # Check rate limits
        if not _check_rate_limit():
            raise HTTPException(status_code=429, detail="Rate limit exceeded")
        
        # Perform fact-checking
        fact_check_result = await _perform_fact_check(
            claim, context, source_priority, include_confidence, detailed_analysis
        )
        
        return MCPToolResponse(
            content=[{
                "type": "text",
                "text": json.dumps(fact_check_result, indent=2)
            }]
        )
        
    except Exception as e:
        logger.error(f"Error fact-checking: {e}")
        return MCPToolResponse(
            content=[{
                "type": "text",
                "text": f"Error fact-checking: {str(e)}"
            }],
            is_error=True
        )

@app.post("/mcp/tools/trending_search/call")
async def tool_trending_search(request: MCPToolCallRequest) -> MCPToolResponse:
    """Find trending topics and current events"""
    try:
        category = request.arguments.get("category", "general")
        region = request.arguments.get("region", "global")
        time_frame = request.arguments.get("time_frame", "day")
        include_analysis = request.arguments.get("include_analysis", True)
        max_trends = request.arguments.get("max_trends", 10)
        
        # Get trending topics
        trends = await _get_trending_topics(category, region, time_frame, include_analysis, max_trends)
        
        return MCPToolResponse(
            content=[{
                "type": "text",
                "text": json.dumps(trends, indent=2)
            }]
        )
        
    except Exception as e:
        logger.error(f"Error getting trends: {e}")
        return MCPToolResponse(
            content=[{
                "type": "text",
                "text": f"Error getting trends: {str(e)}"
            }],
            is_error=True
        )

# Helper functions
async def _search_with_perplexity_api(query: str, focus: str, recency: str, 
                                     max_results: int, language: str) -> List[Dict]:
    """Search using real Perplexity API"""
    try:
        headers = {
            "Authorization": f"Bearer {PERPLEXITY_API_KEY}",
            "Content-Type": "application/json"
        }
        
        # Build the request based on focus
        messages = [
            {
                "role": "user",
                "content": f"Search and provide comprehensive information about: {query}"
            }
        ]
        
        if focus == "academic":
            messages[0]["content"] += " Focus on academic and scholarly sources."
        elif focus == "news":
            messages[0]["content"] += " Focus on recent news and current events."
        elif focus == "technical":
            messages[0]["content"] += " Focus on technical and detailed information."
        
        payload = {
            "model": "llama-3.1-sonar-large-128k-online",
            "messages": messages,
            "max_tokens": 1000,
            "temperature": 0.1,
            "return_citations": True,
            "search_domain_filter": [],
            "search_recency_filter": recency
        }
        
        async with httpx.AsyncClient(timeout=30.0) as client:
            response = await client.post(
                f"{PERPLEXITY_API_BASE}/chat/completions",
                headers=headers,
                json=payload
            )
            
            if response.status_code == 200:
                data = response.json()
                content = data["choices"][0]["message"]["content"]
                citations = data.get("citations", [])
                
                return [{
                    "content": content,
                    "sources": citations[:max_results],
                    "model": "perplexity-pro",
                    "timestamp": datetime.now().isoformat(),
                    "query": query,
                    "focus": focus
                }]
            else:
                logger.error(f"Perplexity API error: {response.status_code} - {response.text}")
                return _simulate_perplexity_search(query, focus, recency, max_results, True)
                
    except Exception as e:
        logger.error(f"Error calling Perplexity API: {e}")
        return _simulate_perplexity_search(query, focus, recency, max_results, True)

def _simulate_perplexity_search(query: str, focus: str, recency: str, 
                               max_results: int, include_sources: bool) -> List[Dict]:
    """Simulate Perplexity search when API is not available"""
    
    simulated_results = []
    
    # Base result
    base_result = {
        "query": query,
        "focus": focus,
        "content": f"üîç **Recherche simul√©e pour**: {query}\n\n",
        "timestamp": datetime.now().isoformat(),
        "simulated": True
    }
    
    if focus == "academic":
        base_result["content"] += "**Sources acad√©miques et recherches:**\n"
        base_result["content"] += "‚Ä¢ Des √©tudes r√©centes montrent des d√©veloppements significatifs\n"
        base_result["content"] += "‚Ä¢ Les experts dans le domaine sugg√®rent...\n"
        base_result["content"] += "‚Ä¢ Les publications peer-reviewed indiquent...\n"
    elif focus == "news":
        base_result["content"] += "**Actualit√©s r√©centes:**\n"
        base_result["content"] += "‚Ä¢ D√©veloppements r√©cents dans ce domaine\n"
        base_result["content"] += "‚Ä¢ Impact sur l'industrie et la soci√©t√©\n"
        base_result["content"] += "‚Ä¢ R√©actions des experts et parties prenantes\n"
    elif focus == "technical":
        base_result["content"] += "**Informations techniques d√©taill√©es:**\n"
        base_result["content"] += "‚Ä¢ Sp√©cifications et d√©tails techniques\n"
        base_result["content"] += "‚Ä¢ Impl√©mentations et cas d'usage\n"
        base_result["content"] += "‚Ä¢ Meilleures pratiques et recommandations\n"
    else:
        base_result["content"] += "**Informations g√©n√©rales:**\n"
        base_result["content"] += "‚Ä¢ Vue d'ensemble du sujet\n"
        base_result["content"] += "‚Ä¢ Points cl√©s et √©l√©ments importants\n"
        base_result["content"] += "‚Ä¢ Contexte et implications\n"
    
    base_result["content"] += f"\n‚ö†Ô∏è **Note**: Cette recherche est simul√©e car l'API Perplexity Pro n'est pas configur√©e. "
    base_result["content"] += "Pour des r√©sultats r√©els, veuillez fournir une cl√© API Perplexity."
    
    if include_sources:
        base_result["sources"] = [
            {"url": "https://example.com/source1", "title": "Source acad√©mique exemple", "snippet": "Extrait de source..."},
            {"url": "https://example.com/source2", "title": "Article de r√©f√©rence", "snippet": "Information pertinente..."},
            {"url": "https://example.com/source3", "title": "Documentation officielle", "snippet": "D√©tails techniques..."}
        ]
    
    simulated_results.append(base_result)
    
    return simulated_results

async def _conduct_comprehensive_research(topic: str, depth: str, perspective: str,
                                        include_recent: bool, include_context: bool,
                                        target_audience: str) -> Dict[str, Any]:
    """Conduct comprehensive research on a topic"""
    
    research_sections = []
    
    # Overview section
    research_sections.append({
        "section": "Overview",
        "content": f"Recherche approfondie sur: **{topic}**\n\n"
                  f"Cette recherche est conduite avec un niveau de d√©tail '{depth}' "
                  f"et une perspective '{perspective}' pour un public '{target_audience}'."
    })
    
    # Context section
    if include_context:
        research_sections.append({
            "section": "Context & Background",
            "content": "‚Ä¢ Contexte historique et √©volution\n"
                      "‚Ä¢ Facteurs cl√©s et influences\n"
                      "‚Ä¢ D√©finitions et concepts importants"
        })
    
    # Main research content
    if depth == "overview":
        research_sections.append({
            "section": "Key Points",
            "content": "‚Ä¢ Points essentiels du sujet\n"
                      "‚Ä¢ Informations de base\n"
                      "‚Ä¢ Conclusions principales"
        })
    elif depth == "detailed":
        research_sections.extend([
            {
                "section": "Detailed Analysis",
                "content": "‚Ä¢ Analyse approfondie des aspects principaux\n"
                          "‚Ä¢ Donn√©es et statistiques pertinentes\n"
                          "‚Ä¢ Comparaisons et contrastes"
            },
            {
                "section": "Expert Perspectives",
                "content": "‚Ä¢ Opinions d'experts dans le domaine\n"
                          "‚Ä¢ D√©bats et controverses\n"
                          "‚Ä¢ Consensus et divergences"
            }
        ])
    elif depth == "comprehensive":
        research_sections.extend([
            {
                "section": "Comprehensive Analysis",
                "content": "‚Ä¢ Analyse exhaustive multi-dimensionnelle\n"
                          "‚Ä¢ Donn√©es quantitatives et qualitatives\n"
                          "‚Ä¢ M√©thodologies et approches"
            },
            {
                "section": "Multiple Perspectives",
                "content": "‚Ä¢ Perspectives acad√©miques\n"
                          "‚Ä¢ Points de vue industriels\n"
                          "‚Ä¢ Implications soci√©tales"
            },
            {
                "section": "Future Implications",
                "content": "‚Ä¢ Tendances √©mergentes\n"
                          "‚Ä¢ Projections et pr√©dictions\n"
                          "‚Ä¢ D√©fis et opportunit√©s"
            }
        ])
    
    # Recent developments
    if include_recent:
        research_sections.append({
            "section": "Recent Developments",
            "content": "‚Ä¢ D√©veloppements r√©cents (derniers mois)\n"
                      "‚Ä¢ Actualit√©s et √©v√©nements marquants\n"
                      "‚Ä¢ Innovations et perc√©es"
        })
    
    # Add simulation notice
    research_sections.append({
        "section": "Note",
        "content": "‚ö†Ô∏è Cette recherche est g√©n√©r√©e de mani√®re simul√©e. "
                  "Pour des r√©sultats de recherche r√©els et √† jour, "
                  "veuillez configurer l'API Perplexity Pro."
    })
    
    return {
        "topic": topic,
        "research_parameters": {
            "depth": depth,
            "perspective": perspective,
            "include_recent": include_recent,
            "include_context": include_context,
            "target_audience": target_audience
        },
        "sections": research_sections,
        "timestamp": datetime.now().isoformat(),
        "simulated": not _has_api_key()
    }

async def _perform_fact_check(claim: str, context: str, source_priority: str,
                             include_confidence: bool, detailed_analysis: bool) -> Dict[str, Any]:
    """Perform fact-checking on a claim"""
    
    fact_check_result = {
        "claim": claim,
        "context": context,
        "verification_status": "simulated",
        "confidence_score": 0.7 if include_confidence else None,
        "analysis": {
            "claim_breakdown": "Analyse des √©l√©ments de la d√©claration",
            "source_verification": "V√©rification avec sources fiables",
            "evidence_assessment": "√âvaluation des preuves disponibles"
        },
        "sources_consulted": [
            {"type": "academic", "count": 3},
            {"type": "news", "count": 5},
            {"type": "official", "count": 2}
        ] if source_priority == "all" else [],
        "verdict": "N√©cessite v√©rification avec API r√©elle",
        "timestamp": datetime.now().isoformat(),
        "simulated": True
    }
    
    if detailed_analysis:
        fact_check_result["detailed_analysis"] = {
            "methodology": "Approche syst√©matique de v√©rification",
            "evidence_quality": "√âvaluation de la qualit√© des preuves",
            "limitations": "Limitations de l'analyse simul√©e",
            "recommendations": "Recommandations pour v√©rification approfondie"
        }
    
    fact_check_result["note"] = ("‚ö†Ô∏è Cette v√©rification est simul√©e. "
                                "Pour une v√©rification factuelle r√©elle, "
                                "veuillez configurer l'API Perplexity Pro.")
    
    return fact_check_result

async def _get_trending_topics(category: str, region: str, time_frame: str,
                              include_analysis: bool, max_trends: int) -> Dict[str, Any]:
    """Get trending topics (simulated without API)"""
    
    # Simulated trending topics
    simulated_trends = [
        {"topic": "Intelligence Artificielle", "growth": "+150%", "category": "tech"},
        {"topic": "D√©veloppement Durable", "growth": "+80%", "category": "environment"},
        {"topic": "Cybers√©curit√©", "growth": "+120%", "category": "tech"},
        {"topic": "Sant√© Num√©rique", "growth": "+90%", "category": "health"},
        {"topic": "√ânergie Renouvelable", "growth": "+110%", "category": "environment"}
    ]
    
    # Filter by category if specified
    if category != "general":
        simulated_trends = [t for t in simulated_trends if t["category"] == category]
    
    # Limit results
    simulated_trends = simulated_trends[:max_trends]
    
    trends_result = {
        "trends": simulated_trends,
        "search_parameters": {
            "category": category,
            "region": region,
            "time_frame": time_frame,
            "max_trends": max_trends
        },
        "timestamp": datetime.now().isoformat(),
        "simulated": True
    }
    
    if include_analysis:
        trends_result["analysis"] = {
            "trend_summary": "Analyse des tendances principales",
            "growth_patterns": "Patterns de croissance observ√©s",
            "regional_variations": "Variations selon les r√©gions",
            "prediction": "Pr√©dictions pour les prochaines semaines"
        }
    
    trends_result["note"] = ("‚ö†Ô∏è Ces tendances sont simul√©es. "
                            "Pour des donn√©es de tendances r√©elles, "
                            "veuillez configurer l'API Perplexity Pro.")
    
    return trends_result

@app.post("/mcp/close")
async def close_mcp_session(request: Dict[str, str]):
    """Close MCP session"""
    session_id = request.get("session_id")
    if session_id in active_sessions:
        session_stats = active_sessions[session_id]
        logger.info(f"üîå Perplexity Session closed: {session_id} "
                   f"(searches: {session_stats['search_count']}, "
                   f"research: {session_stats['research_count']})")
        del active_sessions[session_id]
    
    return {"status": "closed", "session_id": session_id}

@app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {
        "status": "healthy",
        "server": "advanced-mcp-perplexity",
        "version": "2.0.0",
        "active_sessions": len(active_sessions),
        "api_available": _has_api_key(),
        "rate_limit_remaining": RATE_LIMIT_PER_MINUTE - len([
            req for req in request_history 
            if datetime.now() - req < timedelta(minutes=1)
        ]),
        "timestamp": datetime.now().isoformat()
    }

if __name__ == "__main__":
    logger.info("üîç Starting Advanced MCP Perplexity Server...")
    if not _has_api_key():
        logger.warning("‚ö†Ô∏è Perplexity API key not found. Running in simulation mode.")
        logger.info("üí° Set PERPLEXITY_API_KEY environment variable for real functionality.")
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=PERPLEXITY_SERVER_PORT,
        log_level="info"
    )